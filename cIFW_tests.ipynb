{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous IFW method changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aims of a single function (+ parallelised)\n",
    "- Calculate independent entropy of *significant feature*\n",
    "- Calculate I (entropic) between that feature and those in sign_comp (significant interactions)\n",
    "- Output information-theoretical omega\n",
    "- When parallelised, recreate matrix as with bIFW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy calculation for toy genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from os.path import exists\n",
    "import multiprocess\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from p_tqdm import p_map\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import quad\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.2, 0.2, 0.2, 0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "for i in range(4):\n",
    "    f1.append(0.2)\n",
    "f1.append(0)\n",
    "for i in range(8):\n",
    "    f1.append(0.8)\n",
    "for i in range(3):\n",
    "    f1.append(0)\n",
    "\n",
    "f2 = []\n",
    "for i in range(3):\n",
    "    f2.append(1)\n",
    "f2.append(0)\n",
    "for i in range(10):\n",
    "    f2.append(1)\n",
    "for i in range(2):\n",
    "    f2.append(0)\n",
    "    \n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.2, 0.2, 0.2, 0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create toy data\n",
    "def toy_gene(numbers, values):\n",
    "    gene = []\n",
    "    for i, n in enumerate(numbers):\n",
    "        for times in range(n):\n",
    "            gene.append(values[i])\n",
    "    return gene\n",
    "\n",
    "toy_gene([4,1,8,3], [0.2,0,0.8,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_entropy(f1, alternative_entropy = False, evaluation_check = False):\n",
    "    feature = f1    \n",
    "    p0 = np.sum(feature == 0) / len(feature) if len(feature) > 0 else 0\n",
    "    # Probability of zero\n",
    "    non_zero_data = feature[feature != 0]\n",
    "\n",
    "    # KDE for the non-zero part\n",
    "    kde = gaussian_kde(non_zero_data)\n",
    "\n",
    "    # Get the normalization factor by integrating KDE over the range of non-zero values\n",
    "    #kde_normalisation_factor, _ = quad(lambda x: kde(x), 0, max(feature))\n",
    "\n",
    "    # Combined PDF\n",
    "    def combined_pdf(x):\n",
    "        if x == 0:\n",
    "            return p0 #/ kde_normalisation_factor\n",
    "        else:\n",
    "            return (1 - p0) * kde(x) #/ kde_normalisation_factor # sometimes we don't need it, but it helps\n",
    "\n",
    "    integration_result, _ = quad(combined_pdf, 0, max(feature))\n",
    "\n",
    "    # Check normalization (should be close to 1)\n",
    "    normalisation_result = integration_result + p0  # Add p0 for the zero-inflated part\n",
    "    if normalisation_result > 1 or normalisation_result < 0.95:\n",
    "        print(f'\\nNormalisation check unsuccessful. It should be close to 1 and it equals {normalisation_result}. This can lead to negative entropies. Proceeding with using summation instead of integration.')\n",
    "\n",
    "    \n",
    "    # Safe logarithm function\n",
    "    def safe_log(x):\n",
    "        return np.log(x) if x > 0 else 0\n",
    "\n",
    "    # Combined PDF with log for entropy calculation\n",
    "    def combined_pdf_log(x):\n",
    "        fx = combined_pdf(x)\n",
    "        return -fx * safe_log(fx)\n",
    "    \n",
    "    entropy_non_zero, _ = quad(combined_pdf_log, 0, max(feature))\n",
    "    entropy_zero = -p0 * safe_log(p0)\n",
    "    entropy = entropy_non_zero + entropy_zero\n",
    "\n",
    "    if alternative_entropy == False:\n",
    "        return entropy\n",
    "    \n",
    "    if alternative_entropy == True:\n",
    "        # alternative entropy estimation: use sums\n",
    "        x_values = np.arange(0, max(feature) + 1)\n",
    "        pdf_log_values = [combined_pdf_log(x) for x in x_values]\n",
    "        entropy_estimate = np.sum(pdf_log_values)\n",
    "        return entropy, entropy_estimate\n",
    "\n",
    "    if evaluation_check == True:\n",
    "        print(f'\\nNormalisation check, it should be close to 1: {normalisation_result}.')\n",
    "        x_values = np.arange(0, max(feature) + 1)\n",
    "        pdf_values = [combined_pdf(x) for x in x_values[0:np.random.randint(0,len(x_values), 10)]]\n",
    "        log_values = [safe_log(fx) for fx in pdf_values[0:np.random.randint(0,len(x_values), 10)]]\n",
    "        print(\"\\n10 random x values:\", x_values[0:np.random.randint(0,len(x_values), 10)])\n",
    "        print(\"PDF values:\", pdf_values[0:np.random.randint(0,len(x_values), 10)])\n",
    "        print(\"Log values:\", log_values[0:np.random.randint(0,len(x_values), 10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_entropy(f1):\n",
    "    feature = f1\n",
    "    # Probability of zero and data that is nonzero\n",
    "    p0 = np.sum(feature == 0) / len(feature) if len(feature) > 0 else 0\n",
    "    non_zero_data = feature[feature != 0]\n",
    "\n",
    "    # zero  (H1)\n",
    "    def safe_log(x):\n",
    "        return np.log(x) if x > 0 else 0\n",
    "    entropy_zero = -p0 * safe_log(p0)\n",
    "\n",
    "    # H2 (simplified)\n",
    "    # KDE for the non-zero part\n",
    "    kde = gaussian_kde(non_zero_data)\n",
    "    # Simplified kde integration\n",
    "    def h_integrand(fx):\n",
    "        return fx * safe_log(fx)\n",
    "    \n",
    "    kde_part_H2, _ = quad(h_integrand, 0, max(feature))\n",
    "    entropy_non_zero = -h_integrand(1-p0) - (1-p0) * kde_part_H2\n",
    "    \n",
    "    # Combined entropy\n",
    "    entropy = entropy_non_zero + entropy_zero\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_entropy(f1, alternative_entropy = False, evaluation_check = False):\n",
    "    feature = f1 \n",
    "    if isinstance(feature, np.ndarray) == False or np.issubdtype(feature.dtype,np.integer) == False:\n",
    "        feature = np.array(feature.astype(int))\n",
    "    \n",
    "    if len(np.unique(feature)) < 3:\n",
    "        raise ValueError(f\"\\nThere must be more than two unique counts for kde estimation.\")\n",
    "    \n",
    "    p0 = np.sum(feature == 0) / len(feature) if len(feature) > 0 else 0\n",
    "    # Probability of zero\n",
    "    non_zero_data = feature[feature != 0]\n",
    "\n",
    "    # KDE for the non-zero part\n",
    "    kde = gaussian_kde(non_zero_data)\n",
    "\n",
    "    # Get the normalization factor by integrating KDE over the range of non-zero values\n",
    "    #kde_normalisation_factor, _ = quad(lambda x: kde(x), 0, max(feature))\n",
    "\n",
    "    # Combined PDF\n",
    "    def combined_pdf(x):\n",
    "        if x == 0:\n",
    "            return p0 #/ kde_normalisation_factor\n",
    "        else:\n",
    "            return (1 - p0) * kde(x) #/ kde_normalisation_factor # sometimes we don't need it, but it helps\n",
    "\n",
    "    integration_result, _ = quad(combined_pdf, 0, max(feature))\n",
    "\n",
    "    # Check normalization (should be close to 1)\n",
    "    normalisation_result = integration_result + p0  # Add p0 for the zero-inflated part\n",
    "    if normalisation_result > 1 or normalisation_result < 0.95:\n",
    "        print(f'\\nNormalisation check unsuccessful. It should be close to 1 and it equals {normalisation_result}. This can lead to negative entropies. Proceeding with using summation instead of integration.')\n",
    "\n",
    "    \n",
    "    # Safe logarithm function\n",
    "    def safe_log(x):\n",
    "        return np.log(x) if x > 0 else 0\n",
    "\n",
    "    # Combined PDF with log for entropy calculation\n",
    "    def combined_pdf_log(x):\n",
    "        fx = combined_pdf(x)\n",
    "        return -fx * safe_log(fx)\n",
    "    \n",
    "    entropy_non_zero, _ = quad(combined_pdf_log, 0, max(feature))\n",
    "    entropy_zero = -p0 * safe_log(p0)\n",
    "    entropy = entropy_non_zero + entropy_zero\n",
    "\n",
    "    if alternative_entropy == False:\n",
    "        return entropy\n",
    "    \n",
    "    if alternative_entropy == True:\n",
    "        # alternative entropy estimation: use sums\n",
    "        x_values = np.arange(0, max(feature) + 1)\n",
    "        pdf_log_values = [combined_pdf_log(x) for x in x_values]\n",
    "        entropy_estimate = np.sum(pdf_log_values)\n",
    "        return entropy, entropy_estimate\n",
    "\n",
    "    if evaluation_check == True:\n",
    "        print(f'\\nNormalisation check, it should be close to 1: {normalisation_result}.')\n",
    "        x_values = np.arange(0, max(feature) + 1)\n",
    "        pdf_values = [combined_pdf(x) for x in x_values[0:np.random.randint(0,len(x_values), 10)]]\n",
    "        log_values = [safe_log(fx) for fx in pdf_values[0:np.random.randint(0,len(x_values), 10)]]\n",
    "        print(\"\\n10 random x values:\", x_values[0:np.random.randint(0,len(x_values), 10)])\n",
    "        print(\"PDF values:\", pdf_values[0:np.random.randint(0,len(x_values), 10)])\n",
    "        print(\"Log values:\", log_values[0:np.random.randint(0,len(x_values), 10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalisation check unsuccessful. It should be close to 1 and it equals 0.716669630846595. This can lead to negative entropies. Proceeding with using summation instead of integration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5668066919556543"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_gene1 = toy_gene([4,1,8,3], [0.2,0,0.8,0])\n",
    "toy_entropy(np.array(toy_gene1), alternative_entropy = False, evaluation_check = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7358895969342187"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_gene1 = toy_gene([4,1,8,3], [0.2,0,0.8,0])\n",
    "simple_entropy(np.array(toy_gene1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per run: 0.0000002639 seconds\n"
     ]
    }
   ],
   "source": [
    "# how fast are these functions?\n",
    "import timeit\n",
    "\n",
    "def my_function():\n",
    "    # Your short function\n",
    "    pass\n",
    "\n",
    "# Measure the average execution time over 1,000,000 runs\n",
    "execution_time = timeit.timeit(my_function, number=1_000_000)\n",
    "print(f\"Average time per run: {execution_time / 1_000_000:.10f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m \u001b[43mtimeit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msimple_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoy_gene1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage time per run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecution_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1_000_000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.10f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sergi\\anaconda3\\Lib\\timeit.py:234\u001b[0m, in \u001b[0;36mtimeit\u001b[1;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeit\u001b[39m(stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, timer\u001b[38;5;241m=\u001b[39mdefault_timer,\n\u001b[0;32m    232\u001b[0m            number\u001b[38;5;241m=\u001b[39mdefault_number, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sergi\\anaconda3\\Lib\\timeit.py:178\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    176\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer, _stmt)\u001b[0m\n",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mtimeit(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43msimple_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoy_gene1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000_000\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage time per run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecution_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1_000_000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.10f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m, in \u001b[0;36msimple_entropy\u001b[1;34m(f1)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mh_integrand\u001b[39m(fx):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fx \u001b[38;5;241m*\u001b[39m safe_log(fx)\n\u001b[1;32m---> 19\u001b[0m kde_part_H2, _ \u001b[38;5;241m=\u001b[39m \u001b[43mquad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_integrand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m entropy_non_zero \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mh_integrand(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp0) \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp0) \u001b[38;5;241m*\u001b[39m kde_part_H2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Combined entropy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:463\u001b[0m, in \u001b[0;36mquad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst, complex_func)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43m_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:575\u001b[0m, in \u001b[0;36m_quad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m infbounds \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 575\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quadpack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qagse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _quadpack\u001b[38;5;241m.\u001b[39m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m, in \u001b[0;36msimple_entropy.<locals>.h_integrand\u001b[1;34m(fx)\u001b[0m\n\u001b[0;32m     14\u001b[0m kde \u001b[38;5;241m=\u001b[39m gaussian_kde(non_zero_data)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Simplified kde integration\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mh_integrand\u001b[39m(fx):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fx \u001b[38;5;241m*\u001b[39m safe_log(fx)\n\u001b[0;32m     19\u001b[0m kde_part_H2, _ \u001b[38;5;241m=\u001b[39m quad(h_integrand, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m(feature))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "execution_time = timeit.timeit(lambda: simple_entropy(np.array(toy_gene1)), number=1_000_000)\n",
    "print(f\"Average time per run: {execution_time / 1_000_000:.10f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation metric cIFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shape: (3000, 2546). Proceeding to obtain indices for efficient ESS calculation.\n",
      "\n",
      "Indices obtained. Proceeding with calculating ESSs in parallel.\n",
      "\n",
      "Cores Available: 8\n",
      "Cores Used: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0664eea3bbc45b1b71e059edfdaed62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations complete. Proceeding with matrix reconstruction.\n",
      "\n",
      "Matrix construction complete. Saving to dataframe.\n"
     ]
    }
   ],
   "source": [
    "#### Omega (Ω), the correlation metric, formerly Entropy Sort Score (ESS)\n",
    "\n",
    "# The individual function to calculate the Omega score for a given feature\n",
    "def bIFW_correlation(feature_ind, sign_comp, normalised_matrix, extra_vectors = False, zero_info = True, extra_info = False):\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    # get the list of significant features\n",
    "    sign_list = [feat[1] for feat in sign_comp if feat[0] == feature_ind][0]\n",
    "    MI_vector = []\n",
    "    S_q_vector = []\n",
    "    S_m_vector = []\n",
    "    f1 = np.array(normalised_matrix.iloc[:,feature_ind])\n",
    "    \n",
    "    for i in sign_list:\n",
    "        #define feature 2\n",
    "        f2 = np.array(normalised_matrix.iloc[:,i])\n",
    "        n00 = 0\n",
    "        n01 = 0\n",
    "        n10 = 0\n",
    "        n11 = 0\n",
    "        \n",
    "        if len(f1) != len(f2):\n",
    "            print(\"Fixed feature and features from matrix must be of the same length (same n of cells).\")\n",
    "        else:\n",
    "            c = len(f1)\n",
    "            for (cell1, cell2) in zip(f1, f2):\n",
    "                if cell1 == cell2:\n",
    "                    if cell1 == 0:\n",
    "                        n00 += 1\n",
    "                    elif cell1 == 1:\n",
    "                        n11 += 1\n",
    "                        \n",
    "                elif cell1 == 0:\n",
    "                    if cell2 == 1:\n",
    "                        n01 += 1\n",
    "                        \n",
    "                elif cell1 == 1:\n",
    "                    if cell2 == 0:\n",
    "                        n10 += 1\n",
    "                        \n",
    "        # check discretization\n",
    "        ns = np.array([n00, n01, n10, n11])\n",
    "        n_str = [\"n00\", \"n01\", \"n10\", \"n11\"]\n",
    "        nsum = np.sum(ns)\n",
    "        if nsum != c:\n",
    "            print(\"Sum of state counts do not add up.\")\n",
    "            MI = np.nan\n",
    "            S_q = np.nan\n",
    "            S_m = np.nan\n",
    "            \n",
    "        #calculate c's - need to have at least one of each\n",
    "        else:\n",
    "            #wrt to f1\n",
    "            c_m0 = n00 + n01\n",
    "            c_m1 = n10 + n11\n",
    "            #wrt to f2\n",
    "            c_q0 = n00 + n10\n",
    "            c_q1 = n01 + n11\n",
    "            \n",
    "            cs_MI = np.array([[c_m0, c_q0], [c_m0, c_q1],\n",
    "                              [c_m1, c_q0], [c_m1, c_q1]])\n",
    "            cs_S = np.array([[c_m0, c_m1],\n",
    "                             [c_q0, c_q1]])\n",
    "            \n",
    "            MI_terms = []\n",
    "            zeroterms = []\n",
    "            for ind, n in enumerate(ns):\n",
    "                if n != 0 & np.all(cs_MI[ind]) == False: #if n and both cs are nonzero, calculate\n",
    "                    MI_term = (n/c * np.log2(c * n / (cs_MI[ind][0] * cs_MI[ind][1])))\n",
    "                    MI_terms.append(MI_term)\n",
    "                    \n",
    "                else:\n",
    "                    zeroterms.append(n_str[ind])\n",
    "            MI = np.sum(MI_terms)\n",
    "            \n",
    "            # entropies separately\n",
    "            S_m_terms = []\n",
    "            S_q_terms = []\n",
    "            \n",
    "            for ind in range(len(cs_S)):\n",
    "                S_m_terms.append(cs_S[0][ind]/c * np.log2(cs_S[0][ind]/c))\n",
    "                S_q_terms.append(cs_S[1][ind]/c * np.log2(cs_S[1][ind]/c))\n",
    "                \n",
    "            S_m = np.sum(S_m_terms) * (-1)\n",
    "            S_q = np.sum(S_q_terms) * (-1)\n",
    "\n",
    "            if extra_info == True:     \n",
    "                exclude = str()\n",
    "                for t in zeroterms:\n",
    "                    exclude += (t + \", \")\n",
    "                print(\"Be aware that the counts \" + exclude + \"were 0. This affects the calculations.\")\n",
    "                \n",
    "        MI_vector.append(MI)\n",
    "        S_q_vector.append(S_q)\n",
    "        S_m_vector.append(S_m)\n",
    "    \n",
    "    max_entropy = [max(Sm, Sq) for Sm, Sq in zip(S_m_vector, S_q_vector)]\n",
    "    \n",
    "    #now calculate omega\n",
    "    if len(MI_vector) != len(max_entropy):\n",
    "        raise ValueError(\"All vectors (MI, x_max, S_q and S_m) must have the same length\")    \n",
    "\n",
    "    omega_vector = np.array(MI_vector) / np.array(max_entropy)\n",
    "    if extra_vectors == True:\n",
    "        return [omega_vector, MI_vector, max_entropy]            \n",
    "    else:\n",
    "        return [omega_vector]\n",
    "    \n",
    "    \n",
    "# The parallelised function to calculate the Omega for all features\n",
    "def parallel_bIFW_correlation(binarised_data, sign_matrix, Use_Cores=-1):\n",
    "    global binarised_dataset\n",
    "    binarised_dataset = binarised_data\n",
    "    print(f\"Data loaded. Shape: {binarised_dataset.shape}. Proceeding to obtain indices for efficient ESS calculation.\\n\")\n",
    "    nonzero = np.nonzero(sign_matrix.to_numpy())\n",
    "    sign_comp = []\n",
    "    for f in np.unique(nonzero[0]):\n",
    "        #print(f\"Gene {f} has a significant interaction with genes {nonzero[1][nonzero[0] == f]}\")\n",
    "        l = nonzero[1][nonzero[0] == f]\n",
    "        sign_comp.append([f,l])\n",
    "        #print(f\"Gene {f} has a significant interaction with {len(l)} genes\")\n",
    "    Feature_Inds = [feat[0] for feat in sign_comp]\n",
    "    print(f\"Indices obtained. Proceeding with calculating ESSs in parallel.\\n\")\n",
    "    \n",
    "    ## Identify number of cores to use.\n",
    "    Cores_Available = multiprocess.cpu_count()\n",
    "    print(\"Cores Available: \" + str(Cores_Available))\n",
    "    if Use_Cores == -1:\n",
    "        Use_Cores = Cores_Available - 1 # -1 Is an arbitrary buffer of idle cores that I set.\n",
    "        if Use_Cores < 1:\n",
    "            Use_Cores = 1\n",
    "    print(\"Cores Used: \" + str(Use_Cores))\n",
    "    ## Perform calculations\n",
    "    with np.errstate(divide='ignore',invalid='ignore'):\n",
    "        allscores = p_map(partial(bIFW_correlation, sign_comp=sign_comp, normalised_matrix=binarised_dataset), Feature_Inds, num_cpus=Use_Cores)\n",
    "    print(f\"Calculations complete. Proceeding with matrix reconstruction.\\n\")\n",
    "    omega = [row[0] for row in allscores]\n",
    "    \n",
    "    # Use allscores to build square matrix\n",
    "    n = binarised_dataset.shape[1]\n",
    "    indices = (nonzero[0], nonzero[1])\n",
    "    values = [value for sublist in omega for value in sublist]\n",
    "    # Initialize a zero matrix\n",
    "    matrix = np.zeros((n, n), dtype=float)\n",
    "    for row, col, value in zip(indices[0], indices[1], values):\n",
    "        #print(f\"Placing value {value} at position ({row}, {col})\")  # Debug print\n",
    "        matrix[row, col] = value\n",
    "    \n",
    "    print(\"Matrix construction complete. Saving to dataframe.\")\n",
    "    m = pd.DataFrame(matrix)\n",
    "    return allscores, m\n",
    "\n",
    "allscores, omega_matrix = parallel_bIFW_correlation(binarised_data=binarised_df, sign_matrix=chip_masked, Use_Cores=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
